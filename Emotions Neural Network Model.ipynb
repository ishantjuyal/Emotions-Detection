{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "RDftGFUgRQRi",
    "outputId": "f0d23614-b7f4-4bb9-e2f2-f038c0a86b29"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from wordcloud import WordCloud, STOPWORDS \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dict = {'text':[], 'happy':[], 'sad':[], 'fear':[], 'anger':[], 'love':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dUPVcitHv9dR"
   },
   "outputs": [],
   "source": [
    "def get_data(url):\n",
    "    f = open(url, 'r', encoding = \"UTF-8\")\n",
    "    text = f.read()\n",
    "    text_array = text.split('\\n')\n",
    "    emotions = ['happy', 'sad', 'fear', 'anger', 'love']\n",
    "    for sentence in text_array[:-1]:\n",
    "        start_index = sentence.index('>')\n",
    "        end_index = sentence[start_index:].index(\"<\")\n",
    "        text = sentence[start_index + 1:end_index +3]\n",
    "        emotion = sentence[1:start_index]\n",
    "        if emotion in emotions:\n",
    "            text_dict['text'].append(text)\n",
    "            for e in emotions:\n",
    "                if emotion == e:\n",
    "                    text_dict[emotion].append(1)\n",
    "                else:\n",
    "                    text_dict[e].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_2(url):\n",
    "    f = open(url, 'r', encoding = \"UTF-8\")\n",
    "    text = f.read()\n",
    "    text_array = text.split('\\n')\n",
    "    emotions = ['happy', 'sad', 'fear', 'anger', 'love']\n",
    "    emotion_dict = {\"anger\": 6, \"joy\":1, \"fear\":4, \"sadness\":2, \"love\":8, \"surprise\":3}\n",
    "    for sentence in text_array:\n",
    "        if ';' in sentence:\n",
    "            a = sentence.split(';')\n",
    "            text = a[0]\n",
    "            emotion = a[1]\n",
    "            if emotion == 'joy':\n",
    "                emotion = 'happy'\n",
    "            if emotion == 'sadness':\n",
    "                emotion = 'sad'\n",
    "            \n",
    "            if emotion in emotions:\n",
    "                text_dict['text'].append(text)\n",
    "                for e in emotions:\n",
    "                    if emotion == e:\n",
    "                        text_dict[emotion].append(1)\n",
    "                    else:\n",
    "                        text_dict[e].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gjoZPVaszGQS"
   },
   "outputs": [],
   "source": [
    "get_data('No Cause.txt')\n",
    "get_data_2(\"train.txt\")\n",
    "get_data_2(\"test.txt\")\n",
    "get_data_2(\"val.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(text_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "id": "lU1Un3W-U-kj",
    "outputId": "5faa1a7c-d6f1-4ba8-bb56-9f738538dfb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data is (20580, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>happy</th>\n",
       "      <th>sad</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This did the trick : the boys now have a more ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When Anna left Inspector Aziz , she was much h...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>And though , as Lachlan had planned , they had...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Honestly , I 'm really happy for you</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lesley was totally happy about it</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  happy  sad  fear  anger  \\\n",
       "0  This did the trick : the boys now have a more ...      1    0     0      0   \n",
       "1  When Anna left Inspector Aziz , she was much h...      1    0     0      0   \n",
       "2  And though , as Lachlan had planned , they had...      1    0     0      0   \n",
       "3               Honestly , I 'm really happy for you      1    0     0      0   \n",
       "4                  Lesley was totally happy about it      1    0     0      0   \n",
       "\n",
       "   love  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape of training data is\", train.shape)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "id": "nOBB3kNKgkyV",
    "outputId": "8bdd57c8-2436-44c0-86b2-b6b8ec243208"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9JmlL2GQ2Cx4"
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    for index, row in df.iterrows():\n",
    "        filter_sentence = ''\n",
    "        sentence = row['text']\n",
    "    \n",
    "        # Cleaning the sentence with regex\n",
    "        sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "\n",
    "        # Tokenization\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "\n",
    "        # Stopwords removal\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "        \n",
    "        for words in words:\n",
    "            filter_sentence = filter_sentence  + ' ' + str(lemmatizer.lemmatize(words)).lower()\n",
    "        \n",
    "        df.loc[index, 'text'] = filter_sentence\n",
    "    df = df[['text', 'happy', 'sad', 'fear', 'anger', 'love']]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "l767PGrn2pVS",
    "outputId": "c6d320aa-8efe-40b7-c92f-da69e6e21c86"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>happy</th>\n",
       "      <th>sad</th>\n",
       "      <th>fear</th>\n",
       "      <th>anger</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this trick boy distant friendship david much ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when anna left inspector aziz much happier</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and though lachlan planned expected attack mo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>honestly i really happy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lesley totally happy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  happy  sad  fear  anger  \\\n",
       "0   this trick boy distant friendship david much ...      1    0     0      0   \n",
       "1         when anna left inspector aziz much happier      1    0     0      0   \n",
       "2   and though lachlan planned expected attack mo...      1    0     0      0   \n",
       "3                            honestly i really happy      1    0     0      0   \n",
       "4                               lesley totally happy      1    0     0      0   \n",
       "\n",
       "   love  \n",
       "0     0  \n",
       "1     0  \n",
       "2     0  \n",
       "3     0  \n",
       "4     0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = preprocess(train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train[['happy', 'sad', 'fear', 'anger', 'love']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_new = []\n",
    "for line in X:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    X_new.append(token_list)\n",
    "max_sequence_len = max([len(x) for x in X_new])\n",
    "input_sequences = np.array(pad_sequences(X_new, maxlen=max_sequence_len, padding='pre'))\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "X = input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Dense, LSTM, Bidirectional, Dropout, Flatten\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 35, 8)             131248    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 280)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 1405      \n",
      "=================================================================\n",
      "Total params: 132,653\n",
      "Trainable params: 132,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 8, input_length = X.shape[1]))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics='accuracy')  #(# Pick a loss function and an optimizer)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 1.4572 - accuracy: 0.4005\n",
      "Epoch 2/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 1.0823 - accuracy: 0.6500\n",
      "Epoch 3/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.6024 - accuracy: 0.8553\n",
      "Epoch 4/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.3453 - accuracy: 0.9305\n",
      "Epoch 5/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.2194 - accuracy: 0.9538\n",
      "Epoch 6/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.1531 - accuracy: 0.9675\n",
      "Epoch 7/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.1140 - accuracy: 0.9752\n",
      "Epoch 8/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9810\n",
      "Epoch 9/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.0706 - accuracy: 0.9858\n",
      "Epoch 10/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.0578 - accuracy: 0.9877\n",
      "Epoch 11/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.0482 - accuracy: 0.9897\n",
      "Epoch 12/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.0406 - accuracy: 0.9919\n",
      "Epoch 13/20\n",
      "515/515 [==============================] - 1s 3ms/step - loss: 0.0346 - accuracy: 0.9928\n",
      "Epoch 14/20\n",
      "515/515 [==============================] - 1s 3ms/step - loss: 0.0299 - accuracy: 0.9931\n",
      "Epoch 15/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.0260 - accuracy: 0.9942\n",
      "Epoch 16/20\n",
      "515/515 [==============================] - 1s 3ms/step - loss: 0.0230 - accuracy: 0.9941\n",
      "Epoch 17/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9951\n",
      "Epoch 18/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.0184 - accuracy: 0.9953\n",
      "Epoch 19/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.0162 - accuracy: 0.9956\n",
      "Epoch 20/20\n",
      "515/515 [==============================] - 1s 2ms/step - loss: 0.0147 - accuracy: 0.9958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15a512ff640>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(model.predict(X_test), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [list(i).index(1) for i in list(y_test)]\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model on test set:\n",
      "0.8598153547133139\n",
      "The confusion matrix on test set\n",
      "[[1259   50   27   16   63]\n",
      " [  58 1109   23   41    9]\n",
      " [  32   34  426   23    4]\n",
      " [  21   52   21  495    3]\n",
      " [  78   11    5    6  250]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Accuracy of model on test set:\")\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(\"\\nThe confusion matrix on test set\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "    \n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    filter_sentence = ''\n",
    "    for words in words:\n",
    "        filter_sentence = filter_sentence  + ' ' + str(lemmatizer.lemmatize(words)).lower()\n",
    "        \n",
    "    return(filter_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(text):\n",
    "    text = preprocess_sentence(text)\n",
    "    token_list = tokenizer.texts_to_sequences([text])[0]\n",
    "    zeros = max(0, max_sequence_len - len(token_list))\n",
    "    token_list = [0]*zeros + token_list\n",
    "    token_list = np.array(token_list).reshape(1, max_sequence_len)\n",
    "    index = np.argmax(model.predict(token_list), axis = -1)[0]\n",
    "    \n",
    "    emotions = ['happy', 'sad', 'fear', 'anger', 'love']\n",
    "    return(emotions[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sad'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect(\"I feel tired, sore, and lonely. I just want somebody to hold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect(\"Not great. I feel suicidal and I have no one to talk to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect(\"Happy, optimistic, inspired, enthusiastic, upbeat, silly, joyful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Emotions",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
